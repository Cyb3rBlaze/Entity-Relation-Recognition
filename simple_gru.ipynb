{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import linecache\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGRU(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_path, vocab_path, num_layers=4):\n",
    "        super(SimpleGRU, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        word_embeddings = np.load(embedding_path)\n",
    "        self.vocab = np.load(vocab_path)\n",
    "\n",
    "        self.embedding_layer = nn.Embedding.from_pretrained(torch.from_numpy(word_embeddings).float())\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=num_layers)\n",
    "\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embeddings = self.embedding_layer(x)\n",
    "\n",
    "        final_output = torch.zeros_like(embeddings)\n",
    "        \n",
    "        for i in range(embeddings.shape[1]):\n",
    "            output, hidden = self.gru(embeddings[:,i,:].view(1, 1, -1), hidden)\n",
    "            final_output[:,i,:] = output\n",
    "        \n",
    "        final_output = self.pool(final_output)\n",
    "        final_output = self.sigmoid(final_output)\n",
    "\n",
    "        return final_output.squeeze(2)\n",
    "\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.num_layers, 1, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "    def get_indices(self, string):\n",
    "        indices = []\n",
    "\n",
    "        string_arr = string.split(\" \")\n",
    "\n",
    "        for word in string_arr:\n",
    "            if np.where(self.vocab == word)[0].shape[0] != 0:\n",
    "                indices += [np.where(self.vocab == word)[0]]\n",
    "            else:\n",
    "                indices += [np.array([0])]\n",
    "        \n",
    "        return torch.tensor(indices).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityDataset(Dataset):\n",
    "    # overriden methods\n",
    "    def __init__(self, file_path, model):\n",
    "        self.file_path = file_path\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        with open(self.file_path, \"rbU\") as f:\n",
    "            num_lines = sum(1 for _ in f)\n",
    "        \n",
    "        # don't count first line\n",
    "        return num_lines - 1\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        particular_line = linecache.getline(self.file_path, idx+1)\n",
    "        cleaned_sample = self.clean_up(particular_line)\n",
    "\n",
    "        input_sentence = cleaned_sample[4]\n",
    "        entity1 = cleaned_sample[1]\n",
    "        entity2 = cleaned_sample[2]\n",
    "\n",
    "        sentence_arr = self.model.get_indices(input_sentence)\n",
    "        entity1_arr = self.model.get_indices(entity1)\n",
    "        entity2_arr = self.model.get_indices(entity2)\n",
    "\n",
    "        '''labels = torch.zeros_like(sentence_arr)\n",
    "\n",
    "        for _, word_index in enumerate(sentence_arr):\n",
    "            for entity_index in entity1_arr:\n",
    "                if entity_index == word_index:\n",
    "                    labels[_] = 1\n",
    "            for entity_index in entity2_arr:\n",
    "                if entity_index == word_index:\n",
    "                    labels[_] = 1'''\n",
    "\n",
    "        labels1 = self.generate_labels(sentence_arr, entity1_arr)\n",
    "        labels2 = self.generate_labels(sentence_arr, entity2_arr)\n",
    "\n",
    "        labels = labels1 | labels2\n",
    "\n",
    "        return sentence_arr, labels.type(torch.float32)\n",
    "    \n",
    "\n",
    "    # first instance of entity in sentence\n",
    "    def generate_labels(self, sentence_arr, entity_arr):\n",
    "        correct = []\n",
    "\n",
    "        for _, token in enumerate(sentence_arr):\n",
    "            if _ < sentence_arr.shape[0] - entity_arr.shape[0]:\n",
    "                if token == entity_arr[0]:\n",
    "                    not_equal = False\n",
    "                    for i, val in enumerate(entity_arr):\n",
    "                        if sentence_arr[_+i] != val:\n",
    "                            not_equal = True\n",
    "                    if not not_equal:\n",
    "                        correct += [_]\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        labels = torch.zeros_like(sentence_arr)\n",
    "        for i in correct:\n",
    "            labels[i:i+entity_arr.shape[0]] = 1\n",
    "        \n",
    "        return labels\n",
    "        \n",
    "\n",
    "    # helper\n",
    "    def clean_up(self, line):\n",
    "        remove_chars = [\"<e1>\", \"</e1>\", \"<e2>\", \"</e2>\"]\n",
    "\n",
    "        line = line.strip()\n",
    "\n",
    "        for char in remove_chars:\n",
    "            line = line.replace(char, \"\")\n",
    "        \n",
    "        # string clean up\n",
    "        line = re.sub(r'[^a-zA-Z1-9\\s]', '', line)\n",
    "        line = re.sub(' +', ' ', line)\n",
    "        line = line.lower()\n",
    "\n",
    "        line_data = line.split(\"\\t\")\n",
    "        \n",
    "        return line_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "test_string = \"hello how are you\"\n",
    "\n",
    "model = SimpleGRU(50, \"utils/embs_npa.npy\", \"utils/vocab_npa.npy\")\n",
    "\n",
    "indices = model.get_indices(test_string)\n",
    "\n",
    "print(indices.shape)\n",
    "\n",
    "start_hidden = model.init_hidden()\n",
    "output = model(indices.unsqueeze(0), start_hidden)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11013/1136066156.py:10: DeprecationWarning: 'U' mode is deprecated\n",
      "  with open(self.file_path, \"rbU\") as f:\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "\n",
    "dataset = EntityDataset('data/en_corpora_test.txt', model)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11013/1136066156.py:10: DeprecationWarning: 'U' mode is deprecated\n",
      "  with open(self.file_path, \"rbU\") as f:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[189584,     17,     31,   2490,   1139,    777,   1349,      8,  48947,\n",
      "            747,      8,    949,      2,    777,   5711,      5,   1486,  13356,\n",
      "           6639,   3824,    281,  44075,   7302,      7,    686,      0,   4684,\n",
      "           6851,   6639]]), tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]])]\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(train_loader))\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11013/1136066156.py:10: DeprecationWarning: 'U' mode is deprecated\n",
      "  with open(self.file_path, \"rbU\") as f:\n",
      "  0%|          | 1/5461 [00:00<27:15,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8746582269668579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 51/5461 [00:15<24:24,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7528480887413025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 101/5461 [00:31<26:05,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7176336050033569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 151/5461 [00:45<21:57,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7151199579238892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 201/5461 [01:00<31:06,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6894572973251343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 251/5461 [01:15<23:27,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6850866675376892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 302/5461 [01:33<24:23,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6643531918525696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 351/5461 [01:49<30:26,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6368778347969055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 401/5461 [02:04<27:39,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5844876170158386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 451/5461 [02:20<24:52,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5559438467025757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 501/5461 [02:35<28:34,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5631774067878723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 551/5461 [02:52<20:28,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4965883493423462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 601/5461 [03:08<20:05,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47169849276542664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 651/5461 [03:24<29:41,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4506806433200836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 701/5461 [03:40<29:28,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5040118098258972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 751/5461 [03:55<23:16,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4600246548652649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 801/5461 [04:11<25:42,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5288750529289246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 851/5461 [04:27<24:21,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41640231013298035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 901/5461 [04:41<20:58,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43765848875045776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 951/5461 [04:57<24:15,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4671437442302704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1002/5461 [05:13<22:11,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46147453784942627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1051/5461 [05:28<18:02,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4397002160549164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1101/5461 [05:44<30:25,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3948560953140259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1151/5461 [05:59<19:17,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44869381189346313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1201/5461 [06:15<20:19,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5957033038139343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1251/5461 [06:33<21:20,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4940255284309387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1301/5461 [06:48<21:41,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5244684815406799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1321/5461 [06:54<19:08,  3.61it/s]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for _, sample in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input = sample[0]\n",
    "        labels = sample[1]\n",
    "\n",
    "        start_hidden = model.init_hidden()\n",
    "        output = model(input, start_hidden)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if _ % 50 == 0:\n",
    "            print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
